{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Object Detection Demo\n",
    "Welcome to the object detection inference walkthrough!  This notebook will walk you step by step through the process of using a pre-trained model to detect objects in an image. Make sure to follow the [installation instructions](https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/installation.md) before you start."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/r/Workspaces/where-is-my-cat/object_detection/utils/visualization_utils.py:25: UserWarning: \n",
      "This call to matplotlib.use() has no effect because the backend has already\n",
      "been chosen; matplotlib.use() must be called *before* pylab, matplotlib.pyplot,\n",
      "or matplotlib.backends is imported for the first time.\n",
      "\n",
      "The backend was *originally* set to 'module://ipykernel.pylab.backend_inline' by the following code:\n",
      "  File \"/home/r/miniconda3/envs/cat/lib/python3.5/runpy.py\", line 193, in _run_module_as_main\n",
      "    \"__main__\", mod_spec)\n",
      "  File \"/home/r/miniconda3/envs/cat/lib/python3.5/runpy.py\", line 85, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/home/r/miniconda3/envs/cat/lib/python3.5/site-packages/ipykernel/__main__.py\", line 3, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/home/r/miniconda3/envs/cat/lib/python3.5/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n",
      "    app.start()\n",
      "  File \"/home/r/miniconda3/envs/cat/lib/python3.5/site-packages/ipykernel/kernelapp.py\", line 486, in start\n",
      "    self.io_loop.start()\n",
      "  File \"/home/r/miniconda3/envs/cat/lib/python3.5/site-packages/tornado/platform/asyncio.py\", line 127, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"/home/r/miniconda3/envs/cat/lib/python3.5/asyncio/base_events.py\", line 421, in run_forever\n",
      "    self._run_once()\n",
      "  File \"/home/r/miniconda3/envs/cat/lib/python3.5/asyncio/base_events.py\", line 1425, in _run_once\n",
      "    handle._run()\n",
      "  File \"/home/r/miniconda3/envs/cat/lib/python3.5/asyncio/events.py\", line 127, in _run\n",
      "    self._callback(*self._args)\n",
      "  File \"/home/r/miniconda3/envs/cat/lib/python3.5/site-packages/tornado/platform/asyncio.py\", line 117, in _handle_events\n",
      "    handler_func(fileobj, events)\n",
      "  File \"/home/r/miniconda3/envs/cat/lib/python3.5/site-packages/tornado/stack_context.py\", line 276, in null_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/home/r/miniconda3/envs/cat/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 450, in _handle_events\n",
      "    self._handle_recv()\n",
      "  File \"/home/r/miniconda3/envs/cat/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 480, in _handle_recv\n",
      "    self._run_callback(callback, msg)\n",
      "  File \"/home/r/miniconda3/envs/cat/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 432, in _run_callback\n",
      "    callback(*args, **kwargs)\n",
      "  File \"/home/r/miniconda3/envs/cat/lib/python3.5/site-packages/tornado/stack_context.py\", line 276, in null_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/home/r/miniconda3/envs/cat/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n",
      "    return self.dispatch_shell(stream, msg)\n",
      "  File \"/home/r/miniconda3/envs/cat/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 233, in dispatch_shell\n",
      "    handler(stream, idents, msg)\n",
      "  File \"/home/r/miniconda3/envs/cat/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n",
      "    user_expressions, allow_stdin)\n",
      "  File \"/home/r/miniconda3/envs/cat/lib/python3.5/site-packages/ipykernel/ipkernel.py\", line 208, in do_execute\n",
      "    res = shell.run_cell(code, store_history=store_history, silent=silent)\n",
      "  File \"/home/r/miniconda3/envs/cat/lib/python3.5/site-packages/ipykernel/zmqshell.py\", line 537, in run_cell\n",
      "    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n",
      "  File \"/home/r/miniconda3/envs/cat/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2662, in run_cell\n",
      "    raw_cell, store_history, silent, shell_futures)\n",
      "  File \"/home/r/miniconda3/envs/cat/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2785, in _run_cell\n",
      "    interactivity=interactivity, compiler=compiler, result=result)\n",
      "  File \"/home/r/miniconda3/envs/cat/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2903, in run_ast_nodes\n",
      "    if self.run_code(code, result):\n",
      "  File \"/home/r/miniconda3/envs/cat/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2963, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-4-b928cbd8c217>\", line 5, in <module>\n",
      "    from matplotlib import pyplot as plt\n",
      "  File \"/home/r/miniconda3/envs/cat/lib/python3.5/site-packages/matplotlib/pyplot.py\", line 71, in <module>\n",
      "    from matplotlib.backends import pylab_setup\n",
      "  File \"/home/r/miniconda3/envs/cat/lib/python3.5/site-packages/matplotlib/backends/__init__.py\", line 16, in <module>\n",
      "    line for line in traceback.format_stack()\n",
      "\n",
      "\n",
      "  import matplotlib; matplotlib.use('Agg')  # pylint: disable=multiple-statements\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from collections import defaultdict\n",
    "from io import StringIO\n",
    "from matplotlib import pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "from object_detection.utils import label_map_util\n",
    "from object_detection.utils import visualization_utils as vis_util\n",
    "from object_detection.utils import ops as utils_ops\n",
    "\n",
    "if tf.__version__ < '1.4.0':\n",
    "  raise ImportError('Please upgrade your tensorflow installation to v1.4.* or later!')\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model preparation "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variables\n",
    "\n",
    "Any model exported using the `export_inference_graph.py` tool can be loaded here simply by changing `PATH_TO_CKPT` to point to a new .pb file.  \n",
    "\n",
    "By default we use an \"SSD with Mobilenet\" model here. See the [detection model zoo](https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/detection_model_zoo.md) for a list of other models that can be run out-of-the-box with varying speeds and accuracies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to frozen detection graph. This is the actual model that is used for the object detection.\n",
    "PATH_TO_CKPT = 'model/frozen_inference_graph.pb'\n",
    "\n",
    "# List of the strings that is used to add correct label for each box.\n",
    "PATH_TO_LABELS = 'data/mscoco_label_map.pbtxt'\n",
    "\n",
    "#number of classes\n",
    "NUM_CLASSES = 90\n",
    "\n",
    "detection_graph = tf.Graph()\n",
    "with detection_graph.as_default():\n",
    "  od_graph_def = tf.GraphDef()\n",
    "  with tf.gfile.GFile(PATH_TO_CKPT, 'rb') as fid:\n",
    "    serialized_graph = fid.read()\n",
    "    od_graph_def.ParseFromString(serialized_graph)\n",
    "    tf.import_graph_def(od_graph_def, name='')\n",
    "\n",
    "label_map = label_map_util.load_labelmap(PATH_TO_LABELS)\n",
    "categories = label_map_util.convert_label_map_to_categories(label_map, max_num_classes=NUM_CLASSES, use_display_name=True)\n",
    "category_index = label_map_util.create_category_index(categories)\n",
    "\n",
    "def load_image_into_numpy_array(image):\n",
    "  (im_width, im_height) = image.size\n",
    "  return np.array(image.getdata()).reshape(\n",
    "      (im_height, im_width, 3)).astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_class(classes, scores, b_boxes, class_filter, score_filter):\n",
    "    return_list = []\n",
    "    for i in range(classes.shape[0]):\n",
    "        if classes[i]==class_filter and scores[i]>score_filter:\n",
    "            return_list.append({'class':classes[i], 'score':scores[i], 'b_box':b_boxes[i]})\n",
    "    return(return_list)\n",
    "\n",
    "def filter_class_as_lists(classes, scores, b_boxes, class_filter, score_filter):\n",
    "    #import ipdb; ipdb.set_trace() \n",
    "    return_classes = []\n",
    "    return_scores = []\n",
    "    return_b_boxes = []\n",
    "    for i in range(classes.shape[0]):\n",
    "        if classes[i]==class_filter and scores[i]>score_filter:\n",
    "            return_classes.append(classes[i])\n",
    "            return_scores.append(scores[i])\n",
    "            return_b_boxes.append(b_boxes[i])\n",
    "    return(return_classes,return_scores,return_b_boxes)\n",
    "\n",
    "def add_icon_position(original_image, icon_logo,roi_coords):\n",
    "    \n",
    "    rows,cols,channels = original_image.shape\n",
    "    print(\"original image shape: \",  original_image.shape)\n",
    "    print(\"icon logo shape: \", icon_logo.shape)\n",
    "    print(\"input roi: \", roi_coords)\n",
    "\n",
    "    ## Normalized coordinates\n",
    "    (left, right, top, bottom) = (roi_coords[0] * rows, roi_coords[2] * rows, \n",
    "                                  roi_coords[1] * cols, roi_coords[3] * cols)\n",
    "\n",
    "    (left, right, top, bottom) = tuple(map(int,(left, right, top, bottom)))\n",
    "    print(\"converted coords from normalized: \", (left, right, top, bottom))\n",
    "\n",
    "    new_width = right - left\n",
    "    new_height = bottom - top\n",
    "    \n",
    "    print(\"w: \", new_width)\n",
    "    print(\"h: \", new_height)\n",
    "    \n",
    "    icon_logo = cv2.resize(icon_logo, (new_height,new_width))\n",
    "    print(\"icon logo size: \", icon_logo.shape)\n",
    "    roi =  original_image[left:right,top:bottom]\n",
    "    \n",
    "    print(\"new roi shape: \", roi.shape)\n",
    "\n",
    "    # Now create a mask of logo and create its inverse mask also\n",
    "    # in this case, is already B/W\n",
    "    mask = cv2.cvtColor(icon_logo,cv2.COLOR_BGR2GRAY)\n",
    "    print(\"mask shape: \", mask.shape)\n",
    "    mask_inv = cv2.bitwise_not(mask)\n",
    "    print(\"inv mask: shape\", mask_inv)\n",
    "\n",
    "    # Now black-out the area of logo in ROI\n",
    "    original_image_bg = cv2.bitwise_and(roi,roi,mask = mask)\n",
    "\n",
    "    # Take only region of logo from logo image.\n",
    "    icon_logo_fg = cv2.bitwise_and(icon_logo,icon_logo,mask = mask_inv)\n",
    "\n",
    "    # Put logo in ROI and modify the main image\n",
    "    dst = cv2.add(original_image_bg,icon_logo_fg)\n",
    "    original_image[left:right,top:bottom] = dst\n",
    "    \n",
    "    return(original_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'detection_graph' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-94f88bb0abfa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mcap\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mVideoCapture\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m# Running the tensorflow session\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mdetection_graph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdetection_graph\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0msess\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mConfigProto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog_device_placement\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'detection_graph' is not defined"
     ]
    }
   ],
   "source": [
    "width=1920\n",
    "height=1080\n",
    "frame_counter = 0\n",
    "frame_alarm_counter = 24*3\n",
    "last_cat_box=[]\n",
    "import cv2\n",
    "\n",
    "imstack = cv2.imread(\"cat_icon.png\")\n",
    "\n",
    "cap = cv2.VideoCapture(1)\n",
    "# Running the tensorflow session\n",
    "with detection_graph.as_default():\n",
    "    with tf.Session(graph=detection_graph) as sess:\n",
    "        sess = tf.Session(config=tf.ConfigProto(log_device_placement=True))\n",
    "        ret = True\n",
    "        while (ret):\n",
    "            ret,image_np = cap.read()\n",
    "            # Expand dimensions since the model expects images to have shape: [1, None, None, 3]\n",
    "            image_np_expanded = np.expand_dims(image_np, axis=0)\n",
    "            image_tensor = detection_graph.get_tensor_by_name('image_tensor:0')\n",
    "            # Each box represents a part of the image where a particular object was detected.\n",
    "            boxes = detection_graph.get_tensor_by_name('detection_boxes:0')\n",
    "            # Each score represent how level of confidence for each of the objects.\n",
    "            # Score is shown on the result image, together with the class label.\n",
    "            scores = detection_graph.get_tensor_by_name('detection_scores:0')\n",
    "            classes = detection_graph.get_tensor_by_name('detection_classes:0')\n",
    "            num_detections = detection_graph.get_tensor_by_name('num_detections:0')\n",
    "            # Actual detection.\n",
    "            (boxes, scores, classes, num_detections) = sess.run(\n",
    "                [boxes, scores, classes, num_detections],\n",
    "                feed_dict={image_tensor: image_np_expanded})\n",
    "            classes,scores,boxes = filter_class_as_lists(np.squeeze(classes),\n",
    "                                                         np.squeeze(scores),\n",
    "                                                         np.squeeze(boxes),\n",
    "                                                         17,\n",
    "                                                         0.4)\n",
    "            boxes = np.array(boxes)\n",
    "            classes = np.array(classes).astype(np.int32)\n",
    "            num_detections = len(classes)\n",
    "            # Visualization of the results of a detection.\n",
    "            vis_util.visualize_boxes_and_labels_on_image_array(\n",
    "                image_np,\n",
    "                boxes,\n",
    "                classes,\n",
    "                scores,\n",
    "                category_index,\n",
    "                use_normalized_coordinates=True,\n",
    "                line_thickness=8)\n",
    "            \n",
    "            #                   ymin,\n",
    "            #                   xmin,\n",
    "            #                   ymax,\n",
    "            #                   xmax,\n",
    "            \n",
    "            # Found a cat\n",
    "            if any(classes):\n",
    "                last_cat_box = boxes[0]\n",
    "            # No cat, print the cat icon if the last known position of the cat exist\n",
    "            elif any(last_cat_box):\n",
    "                img_cv = add_icon_position(image_np,imstack,last_cat_box)                    \n",
    "                    \n",
    "            img_cv = cv2.resize(image_np,(width,height))\n",
    "#            if not classes and frame_alarm_counter >= frame_counter:\n",
    "#                img_cv = cv2.addWeighted(img_cv,0.7,imstack,0.3,0)\n",
    "#            else:\n",
    "#                frame_counter=0\n",
    "            cv2.imshow('image',img_cv)\n",
    "            frame_counter+=1\n",
    "            if cv2.waitKey(25) & 0xFF == ord('q'):\n",
    "                cv2.destroyAllWindows()\n",
    "                cap.release()\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "img1 = cv2.imread(\"cat_icon.png\")\n",
    "img2 = cv2.imread(\"mesi-vs-ronaldo-1846777.jpg\")\n",
    "img1 = 255 - img1\n",
    "cv2.imshow('res',img1)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "img1 = cv2.imread(\"cat_icon.png\")\n",
    "img1 = cv2.resize(img1,(120,120))\n",
    "img2 = cv2.imread(\"mesi-vs-ronaldo-1846777.jpg\")\n",
    "rows,cols,channels = img1.shape\n",
    "img2[0:rows, 0:cols ] = img1\n",
    "cv2.imshow('res',img2)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 25,  33,  40],\n",
       "        [ 24,  32,  39],\n",
       "        [ 24,  32,  39],\n",
       "        ...,\n",
       "        [ 32,  36,  41],\n",
       "        [ 32,  36,  41],\n",
       "        [ 32,  36,  41]],\n",
       "\n",
       "       [[ 25,  33,  40],\n",
       "        [ 25,  33,  40],\n",
       "        [ 24,  32,  39],\n",
       "        ...,\n",
       "        [ 33,  37,  42],\n",
       "        [ 33,  37,  42],\n",
       "        [ 33,  37,  42]],\n",
       "\n",
       "       [[ 26,  34,  41],\n",
       "        [ 25,  33,  40],\n",
       "        [ 24,  32,  39],\n",
       "        ...,\n",
       "        [ 35,  39,  44],\n",
       "        [ 35,  39,  44],\n",
       "        [ 35,  39,  44]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[ 70,  68, 127],\n",
       "        [ 69,  67, 126],\n",
       "        [ 68,  66, 125],\n",
       "        ...,\n",
       "        [ 50,  55, 104],\n",
       "        [ 49,  54, 103],\n",
       "        [ 47,  52, 101]],\n",
       "\n",
       "       [[ 69,  68, 124],\n",
       "        [ 69,  68, 124],\n",
       "        [ 67,  66, 122],\n",
       "        ...,\n",
       "        [ 50,  55, 104],\n",
       "        [ 49,  54, 103],\n",
       "        [ 47,  52, 101]],\n",
       "\n",
       "       [[ 69,  69, 123],\n",
       "        [ 68,  68, 122],\n",
       "        [ 67,  67, 121],\n",
       "        ...,\n",
       "        [ 50,  55, 104],\n",
       "        [ 49,  54, 103],\n",
       "        [ 47,  52, 101]]], dtype=uint8)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load two images\n",
    "img1 = cv2.imread('mesi-vs-ronaldo-1846777.jpg')\n",
    "img2 = cv2.imread('cat_icon.png')\n",
    "\n",
    "# I want to put logo on top-left corner, So I create a ROI\n",
    "rows,cols,channels = img2.shape\n",
    "roi = img1[0:rows, 0:cols ]\n",
    "roi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_icon_position(original_image, icon_logo,roi_coords):\n",
    "    \n",
    "    rows,cols,channels = original_image.shape\n",
    "\n",
    "    ## Normalized coordinates\n",
    "    (left, right, top, bottom) = (roi_coords[0] * rows, roi_coords[1] * rows, \n",
    "                                  roi_coords[2] * cols, roi_coords[3] * cols)\n",
    "\n",
    "    (left, right, top, bottom) = tuple(map(int,(left, right, top, bottom)))\n",
    "    print(\"converted coords from normalized: \", (left, right, top, bottom))\n",
    "\n",
    "    new_width = right - left\n",
    "    new_height = bottom - top\n",
    "\n",
    "    icon_logo = cv2.resize(icon_logo, (new_width, new_height))\n",
    "    roi =  original_image[top:bottom,left:right]\n",
    "\n",
    "    # Now create a mask of logo and create its inverse mask also\n",
    "    # in this case, is already B/W\n",
    "    mask = cv2.cvtColor(icon_logo,cv2.COLOR_BGR2GRAY)\n",
    "    mask_inv = cv2.bitwise_not(mask)\n",
    "\n",
    "    # Now black-out the area of logo in ROI\n",
    "    original_image_bg = cv2.bitwise_and(roi,roi,mask = mask)\n",
    "\n",
    "    # Take only region of logo from logo image.\n",
    "    icon_logo_fg = cv2.bitwise_and(icon_logo,icon_logo,mask = mask_inv)\n",
    "\n",
    "    # Put logo in ROI and modify the main image\n",
    "    dst = cv2.add(original_image_bg,icon_logo_fg)\n",
    "    original_image[top:bottom,left:right] = dst\n",
    "    \n",
    "    return(original_image)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "converted coords from normalized:  (70, 94, 136, 170)\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "# Load two images\n",
    "img1 = cv2.imread('mesi-vs-ronaldo-1846777.jpg')\n",
    "img2 = cv2.imread('cat_icon.png')\n",
    "new_img = add_icon_position(img1,img2,[0.3,0.4,0.4,0.5])\n",
    "cv2.imshow('res',new_img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "converted coords from normalized:  (0, 117, 0, 170)\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "# Load two images\n",
    "roi_coords = [0,0.5,0,0.5]\n",
    "original_image = cv2.imread('mesi-vs-ronaldo-1846777.jpg')\n",
    "icon_logo = cv2.imread('cat_icon.png')\n",
    "\n",
    "rows,cols,channels = original_image.shape\n",
    "\n",
    "## Normalized coordinates\n",
    "(left, right, top, bottom) = (roi_coords[0] * rows, roi_coords[1] * rows, \n",
    "                              roi_coords[2] * cols, roi_coords[3] * cols)\n",
    "\n",
    "(left, right, top, bottom) = tuple(map(int,(left, right, top, bottom)))\n",
    "print(\"converted coords from normalized: \", (left, right, top, bottom))\n",
    "\n",
    "new_width = right - left\n",
    "new_height = bottom - top\n",
    "\n",
    "icon_logo = cv2.resize(icon_logo, (new_width, new_height))\n",
    "roi =  original_image[top:bottom,left:right]\n",
    "\n",
    "# Now create a mask of logo and create its inverse mask also\n",
    "# in this case, is already B/W\n",
    "mask = cv2.cvtColor(icon_logo,cv2.COLOR_BGR2GRAY)\n",
    "mask_inv = cv2.bitwise_not(mask)\n",
    "\n",
    "# Now black-out the area of logo in ROI\n",
    "original_image_bg = cv2.bitwise_and(roi,roi,mask = mask)\n",
    "\n",
    "# Take only region of logo from logo image.\n",
    "icon_logo_fg = cv2.bitwise_and(icon_logo,icon_logo,mask = mask_inv)\n",
    "\n",
    "# Put logo in ROI and modify the main image\n",
    "dst = cv2.add(original_image_bg,icon_logo_fg)\n",
    "original_image[top:bottom,left:right] = dst\n",
    "\n",
    "cv2.imshow('res',original_image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 2, 3, 3)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mytuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
